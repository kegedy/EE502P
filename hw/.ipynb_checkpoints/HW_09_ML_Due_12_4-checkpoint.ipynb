{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T16:05:23.746666Z",
     "start_time": "2019-09-24T16:05:23.741461Z"
    }
   },
   "source": [
    "## EE 502 P: Analytical Methods for Electrical Engineering\n",
    "    \n",
    "# Homework 9: ML\n",
    "## Due 4 December, 2019 at 6:00 PM\n",
    "### <span style=\"color: red\">YOUR NAME HERE</span>\n",
    "\n",
    "Copyright &copy; 2019, University of Washington\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Instructions**: Use this notebook as a template. Answer all questions using well formatted Markdown with embedded LaTeX equations, executable Jupyter cells, or both. Submit your homework solutions as an `.ipynb` file via Canvas.\n",
    "\n",
    "<span style=\"background: yellow; padding: 6px; border: 1pt solid black\">\n",
    "Although you may discuss the homework with others, you must turn in your own, original work.\n",
    "</span>\n",
    "\n",
    "**Things to remember:**\n",
    "- Use complete sentences. Equations should appear in text as grammatical elements.\n",
    "- Comment your code.\n",
    "- Label your axes. Title your plots. Use legends where appropriate. \n",
    "- Before submitting a notebook, choose Kernel -> Restart and Run All to make sure your notebook runs when the cells are evaluated in order. \n",
    "\n",
    "Note : Late homework will be accepted up to one week after the due date and will be worth 50% of its full credit score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Warmup (Do not turn in)\n",
    "\n",
    "- Make sure you get download, read, and run the notebooks for lecture 9. Work through the notebook cell by cell and see what happens when you change the expressions, and make up some of your own.\n",
    "- Most of the lecture notes come from two sources. The first is the following book:\n",
    "    > Goodfellow, [Deep Learning](http://www.deeplearningbook.org/). \n",
    "\n",
    "  and the other is the pytorch web page. In particular, the [tutorial page](https://pytorch.org/tutorials/) is great. \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. XNOR \n",
    "\n",
    "Recall the two layer network with two inputs and two hidden nodes corresponds to the equations below, where $g$ is the Rectified Linear Unit function. By hand, find weights and biases so that this network computes the XNOR function (instead of XOR as shown in class. \n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} x_3 \\\\ x_4 \\end{pmatrix} = \n",
    "g \\left ( \n",
    "    \\begin{pmatrix}\n",
    "      w_{13} & w_{23} \\\\\n",
    "      w_{14} & w_{24}\n",
    "    \\end{pmatrix}\n",
    "      \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} \n",
    "    + \\begin{pmatrix}b_3 \\\\ b_4\\end{pmatrix} \n",
    "\\right )\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "x_5 = \n",
    "g \\left ( \n",
    "      \\begin{pmatrix} w_{35} & w_{45} \\end{pmatrix}\n",
    "      \\begin{pmatrix} x_3 \\\\ x_4 \\end{pmatrix} \n",
    "    + b_5 \n",
    "\\right )\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$y = x_5$ being the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PyTorch\n",
    "\n",
    "Modify the PyTorch example below so that it learns to classify inputs with a 3x3 checkerboard instead of the 2x2 checkerboard shown in class. You may need to adjust the number of hidden neurons, the number of outer loop iterations, and the number of inner loop iterations. Then answer the following questions:\n",
    "\n",
    "a) What is the effect of changing the learning rate to 0.01?\n",
    "\n",
    "b) What is the effect of changing the learning rate to 0.001?\n",
    "\n",
    "c) What is the effect of using only 2 nodes in the hidden layer? \n",
    "\n",
    "d) What is the effect of using only 2000 nodes in the hidden layer? \n",
    "\n",
    "Note that if this code does not work on your laptop, you probably need to install PyTorch. Alternatively, you could use Google CoLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T23:55:29.283066Z",
     "start_time": "2019-11-28T23:55:20.936875Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "\n",
    "class ModelTwo(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super(ModelTwo, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,size)\n",
    "        self.fc2 = nn.Linear(size,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x),dim=1) \n",
    "        return x\n",
    "    \n",
    "def make_data(n):\n",
    "    x = torch.rand(n,2)\n",
    "    y = torch.tensor([\n",
    "        (q[0]<0.5 and q[1]<0.5) or\n",
    "        (q[0]>0.5 and q[1]>0.5)\n",
    "        for q in x\n",
    "    ],dtype=torch.long)     \n",
    "    return x,y\n",
    "\n",
    "def show_predictions(model, ax):\n",
    "    x,y = make_data(1000)\n",
    "    yhat = model(x)\n",
    "    prediction = torch.argmax(yhat,dim=1) \n",
    "    err = 100 * torch.sum(torch.abs(y - prediction)) / 1000\n",
    "    p = ax.scatter(x[:,0], x[:,1], c=yhat[:,1].detach(), vmin=0, vmax=1)\n",
    "    ax.set_aspect(1)  \n",
    "    ax.set_title(\"%0.1f%% error\" % err)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    plt.colorbar(p)    \n",
    "\n",
    "model = ModelTwo(100)    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "data = []\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "for _ in range(1000):\n",
    "    x,y = make_data(100) \n",
    "    for _ in range(10):\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)\n",
    "        loss = criterion(yhat,y)\n",
    "        data.append(loss)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "ax[0].plot(data)\n",
    "show_predictions(model, ax[1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Literature\n",
    "\n",
    "Read the following three articles and then answer the questions below. Note that if you are not at UW you may need to use the [library proxy system](https://www.lib.washington.edu/help/connect) to get access to these papers.\n",
    "\n",
    "- [Deep Learning](https://www-nature-com.offcampus.lib.washington.edu/articles/nature14539)\n",
    "- [How To Deal With Machine Learning Papers](https://blogs.sciencemag.org/pipeline/archives/2019/11/20/how-to-deal-with-machine-learning-papers)\n",
    "\n",
    "a) Why are local minima not a problem in large neural networks?\n",
    "b) Why might scientists be skeptical of the use neural networks to understand scientific data?\n",
    "c) Computational neural networks were not considered practical in the 1990s. What changed?\n",
    "d) What safety and security issues are unique to the use of neural networks for engineering purposes?\n",
    "e) What are three applications of machine learning you had not heard of that sound interesting to you?\n",
    "f) What are the limitations of deep learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
